# Answer Key

## Section 1: Linear Regression and Its Limitations

1. **Correct Answer:** B  
**Explanation:** OLS regression aims to find the best linear fit to the data.  
**Verbatim Quote:** "A linear regression finds the best linear fit of the data." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)

2. **Correct Answers:** A, B, C  
**Explanation:** OLS is limited by high dimensionality, sparsity, collinearity, and lack of feature selection.  
**Verbatim Quote:** "Not well suited for NLP: High-dimensionality, Sparsity, Collinearity... OLS model has no mechanism for removing unimportant features." (6.3.pdf)

3. **Correct Answer:** B  
**Explanation:** Collinearity makes it difficult to isolate effects, leading to unstable estimates.  
**Verbatim Quote:** "Colinearity... makes it difficult to isolate the effect of one individual feature. This then manifests in unstable estimates..." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)

## Section 2: Lasso Regression and Regularization

4. **Correct Answer:** B  
**Explanation:** Lasso regression introduces L1 regularization, which is the sum of absolute values of coefficients.  
**Verbatim Quote:** "Lasso Regression... Introduces L1 regularization term to OLS loss function... L1 = absolute value of individual OLS coefficients" (6.3.pdf)

5. **Correct Answers:** A, B, C  
**Explanation:** Lasso encourages sparsity, handles high-dimensional data, and overcomes multicollinearity.  
**Verbatim Quote:** "Lasso encourages sparsity in significant coefficients... Works well with high-dimensional data... Overcomes issues with multicollinearity" (6.3.pdf)

6. **Correct Answer:** B  
**Explanation:** Lambda controls the magnitude of the penalty term in Lasso regression.  
**Verbatim Quote:** "The Lambda term... is called the regularization parameter. It's a hyperparameter that controls the magnitude of the penalty." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)

## Section 3: Support Vector Regression (SVR) and Nonlinear Models

7. **Correct Answer:** B  
**Explanation:** SVR can incorporate non-linearities through kernel functions.  
**Verbatim Quote:** "The way that this plane is identified is by introducing non-linearities into the data through something called a kernel function." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)

8. **Correct Answers:** A, B, C  
**Explanation:** SVR uses kernel functions for non-linearities, works well with sparse data, and is less interpretable than Lasso.  
**Verbatim Quote:** "SVR... incorporates nonlinearity... works well with sparse data... less interpretable than Lasso" (6.3.pdf)

9. **Correct Answer:** B  
**Explanation:** SVR is less interpretable than Lasso due to non-linearities.  
**Verbatim Quote:** "The model does have some cons or some downsides though. For one, it is not as interpretable as a Lasso regression." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)

10. **Correct Answers:** A, B, C  
**Explanation:** Regularization penalizes large coefficients, helps mitigate complexity, and L1 encourages sparsity.  
**Verbatim Quote:** "A regularization term is a penalty for individual feature importance... L1 regularization... encourages coefficients to have a value of zero... can help mitigate model complexity." (6.3-Text-Regressions-with-Lasso-and-SVR.txt)
