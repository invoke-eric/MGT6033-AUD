# Quiz Questions

## Section 1: Logit, Probit, and Linear Classifiers

1. **(Easy)** What is a key difference between logit and probit models for classification?  
A. Probit cannot be used for binary outcomes  
B. Logit is only for regression; probit is only for classification  
C. Logit assumes a linear relation with the log odds; probit assumes a linear relation with the cumulative distribution function  
D. Logit always uses non-linear predictors  

2. **(Medium, Select all that apply):** What are limitations of logit and probit models when applied to text-based classification?  
A. Always require multiclass labels  
B. Susceptible to collinearity  
C. Do not include built-in regularization  
D. Assume linearity between input variables and a transformation of the outcome  

3. **(Hard)** Why might logit and probit models be less suitable for high-dimensional NLP tasks compared to other classifiers?  
A. They cannot handle text data at all  
B. They lack mechanisms for identifying important features or regularizing the model  
C. They always require categorical predictors  
D. They are non-parametric  

## Section 2: Decision Trees

4. **(Easy)** What is a decision tree classifier best described as?  
A. A model that emulates a flow-chart style decision process  
B. A linear regression model  
C. A clustering algorithm  
D. A type of neural network  

5. **(Medium, Select all that apply):** What are advantages of decision trees for text-based classification?  
A. Easy to implement and interpret  
B. Captures nonlinearities  
C. Not sensitive to feature scaling  
D. Robbie will give you an A if you use them  

6. **(Hard, Select all that apply):** What are common drawbacks of decision tree classifiers?  
A. Highly prone to overfitting if not pruned  
B. Can be biased by unbalanced data  
C. Cannot handle categorical variables  
D. May require setting a minimum impurity threshold for leaves  

## Section 3: Naive Bayes and Stochastic Gradient Descent

7. **(Medium)** What is the main assumption behind a Naive Bayes classifier?  
A. The model is non-parametric  
B. All features are continuous  
C. Data is always balanced  
D. Features are conditionally independent given the class label  

8. **(Hard, Select all that apply):** What are strengths of the Naive Bayes classifier for text classification?  
A. Regularization for text data  
B. Simple to implement and interpret  
C. Computationally efficient and andles high-dimensional data well  
D. Handles multicollinearity  

9. **(Hard)** What is a key limitation of the Naive Bayes classifier in practice?  
A. The conditional independence assumption is often violated  
B. It cannot be used for spam detection  
C. It always requires regularization  
D. It is only suitable for regression tasks  

10. **(Hard, Select all that apply):** Which statements about stochastic gradient descent (SGD) are correct?  
A. It is an optimization process, not a classifier itself  
B. It is only used for neural networks  
C. It is very fast and can incorporate regularization  
D. It updates parameters using one random observation at a time  

