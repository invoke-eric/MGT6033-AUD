# Answer Key

## Section 1: Transformer Architecture Fundamentals

1. **Correct Answer:** B  
**Explanation:** The lecture explicitly states that the sole learning objective is to discriminate between language transformers and previously employed neural networks, not to design transformers from scratch.  
**Verbatim Quote:** "The sole learning objective is that you can discriminate between language transformers and the previously employed neural networks that we were designing earlier." (7.3a.-Transformers-Revisited.txt)

2. **Correct Answers:** A, B, D, E  
**Explanation:** The lecture identifies four key defining characteristics of transformers: self-attention mechanism, positional encoding, contextual representations, and encoder-decoder architecture. Sequential processing is actually a characteristic of traditional neural networks, not transformers.  
**Verbatim Quote:** "There's four key defining characteristics that I want you to understand the intuition behind. First, transformers have a self attention mechanism... Second and relatedly, transformers rely on positional encoding... Third, transformers capture contextual representations... Fourth, they generally employ an encoder-decoder architecture." (7.3a.-Transformers-Revisited.txt)

3. **Correct Answer:** B  
**Explanation:** The self-attention mechanism allows transformers to weigh the importance of different words in a sequence regardless of their position, understanding dependencies between words that may be far apart.  
**Verbatim Quote:** "This attention mechanism allows the model to weigh the importance of different words or tokens in a sequence. It does this by understanding the dependencies or the relationships between words, regardless of how those appear in a sequence." (7.3a.-Transformers-Revisited.txt)

4. **Correct Answers:** A, B, D  
**Explanation:** Transformers enable parallelization, capture long-range dependencies, and learn context without sequential processing. The lecture doesn't claim they require less training data.  
**Verbatim Quote:** "First, attention allows transformers to learn context without requiring sequential processing. This makes parallelization possible.... This is super important and was the primary innovation in the model." (7.3a.-Transformers-Revisited.txt)

5. **Correct Answer:** A  
**Explanation:** Positional encoding helps the model understand sequence order without requiring word-by-word processing, providing the benefits of sequential processing but much faster.  
**Verbatim Quote:** "By incorporating positional encoding, the model can understand the sequence, but much faster than if each word is fed one at a time." (7.3a.-Transformers-Revisited.txt)

## Section 2: Encoder-Decoder Components

6. **Correct Answer:** A  
**Explanation:** Encoders have two vital components: the self-attention mechanism and a feed-forward artificial neural network with nonlinear activations.  
**Verbatim Quote:** "Encoders... Have two vital components: Self-attention mechanism (as discussed), Feed-forward ANN with nonlinear activations." (7.3a.pdf)

7. **Correct Answers:** A, B, C  
**Explanation:** Decoders unpack contextualized embeddings, include masked self-attention to limit visibility of future words, and contain encoder-decoder attention mechanisms. They do not process tokens sequentially like RNNs.  
**Verbatim Quote:** "Decoders do the opposite. They unpack the contextualized embeddings back into natural language... There's something called masked self-attention... The second type of attention I'll refer to as the encoder-decoder attention mechanism." (7.3a.-Transformers-Revisited.txt)

8. **Correct Answer:** B  
**Explanation:** Masked self-attention limits the model's ability to see words occurring after a given position in the sequence, which is important for tasks like text generation.  
**Verbatim Quote:** "There's something called masked self-attention, and this type of attention limits the model's ability to see words occurring after a sequence. This is important for things like generative text or next-sentence prediction." (7.3a.-Transformers-Revisited.txt)

9. **Correct Answers:** A, B, C  
**Explanation:** Encoders produce contextualized embeddings, decoders generate output based on these representations, and both can be stacked or chained. There's no requirement for equal numbers of layers.  
**Verbatim Quote:** "Encoders produce the contextualized embeddings... Decoders do the opposite. They unpack the contextualized embeddings back into natural language... Both encoders and decoders can be chained together." (7.3a.-Transformers-Revisited.txt)

10. **Correct Answer:** B  
**Explanation:** The encoder-decoder attention mechanism allows the decoder to understand the structure of the original data so that the output is structurally appropriate given the input.  
**Verbatim Quote:** "This is a very high level, but this allows the decoder to understand the basic structure of the original data so that the output structurally matches or is structurally appropriate given that input." (7.3a.-Transformers-Revisited.txt)
