# Answer Key

## Section 1: Design Considerations for Neural Networks in NLP

1. **Correct Answer:** A  
**Explanation:** Traditional representations like bag-of-words and TF-IDF lack context and sequential information, limiting their usefulness for deep learning.  
**Verbatim Quote:** "this representation lacks context and sequential information that can be useful for understanding the true meaning of text." (7.1b.-Neural-Networks-and-NLP.txt)

2. **Correct Answers:** A, B  
**Explanation:** Modern approaches include word embeddings and transformer-based models; bag-of-words and TF-IDF are traditional.  
**Verbatim Quote:** "Nowadays, word embedding such as word vec, which we've seen glove and others, may be used. Alternatively, more complex methods like transformer based models, think BERT, think GPT..." (7.1b.-Neural-Networks-and-NLP.txt)

3. **Correct Answer:** A  
**Explanation:** Keeping original casing can help capture semantic differences and improve performance if enough data is available.  
**Verbatim Quote:** "Cased words or words that retain the original casing can improve model performance given sufficient data." (7.1b.-Neural-Networks-and-NLP.txt)

4. **Correct Answer:** A  
**Explanation:** Many ANNs work better with shorter sequences, so breaking documents up can help model performance.  
**Verbatim Quote:** "Many ANNs work better with shorter sequences. So we may need to decide if we should break our documents up into sentences or paragraphs." (7.1b.-Neural-Networks-and-NLP.txt)

## Section 2: Computational and Training Considerations

5. **Correct Answers:** A, B, C  
**Explanation:** Complexity depends on input dimensionality, network size, and model architecture.  
**Verbatim Quote:** "The dimensionality of our input data, coupled with the number of nodes and layers, is what determines it." (7.1b.-Neural-Networks-and-NLP.txt)

6. **Correct Answer:** A  
**Explanation:** Zero padding and truncation are used to ensure all input sequences are the same length for the model.  
**Verbatim Quote:** "Usually we do something called zero padding or truncation depending on the issue." (7.1b.-Neural-Networks-and-NLP.txt)

7. **Correct Answers:** A, B, C  
**Explanation:** Dropout, weight decay, and using smaller models help mitigate overfitting; ignoring regularization does not.  
**Verbatim Quote:** "Regularization techniques like dropout and weight decay... can help mitigate these issues." (7.1b.-Neural-Networks-and-NLP.txt)

8. **Correct Answer:** A  
**Explanation:** GPUs allow parallel processing with hundreds of cores, making them ideal for deep learning.  
**Verbatim Quote:** "GPUs or Graphic Processing Units have hundreds of cores versus the four or eight cores that our CPUs typically have." (7.1b.-Neural-Networks-and-NLP.txt)

## Section 3: Evaluation and Ethical Considerations

9. **Correct Answer:** A  
**Explanation:** The evaluation metric determines how model performance is monitored and optimized during training.  
**Verbatim Quote:** "the choice of an appropriate evaluation metric like accuracy or an F1 score... is also critical to adequately evaluating the performance of the model." (7.1b.-Neural-Networks-and-NLP.txt)

10. **Correct Answers:** A, B, C  
**Explanation:** Model bias, masking sensitive terms, and testing with feature importance or synthetic data are all important ethical considerations; predictions should not be interpreted as deterministic.  
**Verbatim Quote:** "Models will learn biases... we can make specific choices should things like race or gender... be in the data at all... look at feature importance analysis... look at what happens with synthetic data." (7.1b.-Neural-Networks-and-NLP.txt)
