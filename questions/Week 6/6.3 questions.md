# Quiz Questions

## Section 1: Linear Regression and Its Limitations

1. **(Easy)** What is the primary goal of ordinary least squares (OLS) linear regression?  
A. To find the best nonlinear fit to the data  
B. To find the best linear fit to the data  
C. To maximize the number of features  
D. To minimize the number of features  

2. **(Medium, Select all that apply):** What are major limitations of OLS regression for NLP and high-dimensional textual data?  
A. High dimensionality and sparsity  
B. Collinearity among features  
C. No mechanism for removing unimportant features  
D. Built-in handling of non-linearities  

3. **(Hard)** Why can collinearity among features be problematic in OLS regression?  
A. It makes matrix inversion impossible  
B. It leads to unstable coefficient estimates  
C. It always improves model accuracy  
D. It guarantees all coefficients are zero  

## Section 2: Lasso Regression and Regularization

4. **(Medium)** What type of regularization does Lasso regression introduce to the OLS loss function?  
A. L2 regularization (sum of squared coefficients)  
B. L1 regularization (sum of absolute coefficients)  
C. No regularization  
D. Dropout regularization  

5. **(Hard, Select all that apply):** What are advantages of Lasso regression for textual data?  
A. Encourages sparsity in coefficients  
B. Can handle high-dimensional data  
C. Overcomes issues with multicollinearity  
D. Automatically models non-linearities  

6. **(Hard)** What is the role of the “lambda” hyperparameter in Lasso regression?  
A. It controls the learning rate  
B. It controls the strength of the regularization penalty  
C. It sets the minimum number of features  
D. It determines the number of iterations  

## Section 3: Support Vector Regression (SVR) and Nonlinear Models

7. **(Medium)** What is a key benefit of support vector regression (SVR) compared to OLS and Lasso?  
A. It is always faster to compute  
B. It can incorporate non-linearities using kernel functions  
C. It guarantees perfect interpretability  
D. It requires no hyperparameters  

8. **(Hard, Select all that apply):** Which statements about SVR are correct?  
A. SVR uses kernel functions to introduce non-linearities  
B. SVR works well with sparse data  
C. SVR is less interpretable than Lasso  
D. SVR always produces linear decision boundaries  

9. **(Hard)** What is a limitation of SVR compared to Lasso regression?  
A. SVR cannot handle non-linear relationships  
B. SVR is less interpretable due to non-linearities  
C. SVR cannot process sparse data  
D. SVR always removes unimportant features  

10. **(Hard, Select all that apply):** According to the lecture, which of the following are true about regularization in regression models?  
A. Regularization penalizes large coefficients  
B. Regularization can help mitigate model complexity  
C. L1 regularization encourages sparsity  
D. Regularization is only used in unsupervised models  

