{
  "title": "Quiz Questions",
  "sections": [
    {
      "title": "Section 1: Linear Regression and Its Limitations",
      "questions": [
        {
          "number": 1,
          "difficulty": "Easy",
          "type": "single_select",
          "question": "What is the primary goal of ordinary least squares (OLS) linear regression?",
          "options": {
            "A": "To find the best nonlinear fit to the data",
            "B": "To find the best linear fit to the data",
            "C": "To maximize the number of features",
            "D": "To minimize the number of features"
          }
        },
        {
          "number": 2,
          "difficulty": "Unknown",
          "type": "single_select",
          "question": "**(Medium, Select all that apply):** What are major limitations of OLS regression for NLP and high-dimensional textual data?",
          "options": {
            "A": "High dimensionality and sparsity",
            "B": "Collinearity among features",
            "C": "No mechanism for removing unimportant features",
            "D": "Built-in handling of non-linearities"
          }
        },
        {
          "number": 3,
          "difficulty": "Hard",
          "type": "single_select",
          "question": "Why can collinearity among features be problematic in OLS regression?",
          "options": {
            "A": "It makes matrix inversion impossible",
            "B": "It leads to unstable coefficient estimates",
            "C": "It always improves model accuracy",
            "D": "It guarantees all coefficients are zero"
          }
        }
      ]
    },
    {
      "title": "Section 2: Lasso Regression and Regularization",
      "questions": [
        {
          "number": 4,
          "difficulty": "Medium",
          "type": "single_select",
          "question": "What type of regularization does Lasso regression introduce to the OLS loss function?",
          "options": {
            "A": "L2 regularization (sum of squared coefficients)",
            "B": "L1 regularization (sum of absolute coefficients)",
            "C": "No regularization",
            "D": "Dropout regularization"
          }
        },
        {
          "number": 5,
          "difficulty": "Unknown",
          "type": "single_select",
          "question": "**(Hard, Select all that apply):** What are advantages of Lasso regression for textual data?",
          "options": {
            "A": "Encourages sparsity in coefficients",
            "B": "Can handle high-dimensional data",
            "C": "Overcomes issues with multicollinearity",
            "D": "Automatically models non-linearities"
          }
        },
        {
          "number": 6,
          "difficulty": "Hard",
          "type": "single_select",
          "question": "What is the role of the “lambda” hyperparameter in Lasso regression?",
          "options": {
            "A": "It controls the learning rate",
            "B": "It controls the strength of the regularization penalty",
            "C": "It sets the minimum number of features",
            "D": "It determines the number of iterations"
          }
        }
      ]
    },
    {
      "title": "Section 3: Support Vector Regression (SVR) and Nonlinear Models",
      "questions": [
        {
          "number": 7,
          "difficulty": "Medium",
          "type": "single_select",
          "question": "What is a key benefit of support vector regression (SVR) compared to OLS and Lasso?",
          "options": {
            "A": "It is always faster to compute",
            "B": "It can incorporate non-linearities using kernel functions",
            "C": "It guarantees perfect interpretability",
            "D": "It requires no hyperparameters"
          }
        },
        {
          "number": 8,
          "difficulty": "Unknown",
          "type": "single_select",
          "question": "**(Hard, Select all that apply):** Which statements about SVR are correct?",
          "options": {
            "A": "SVR uses kernel functions to introduce non-linearities",
            "B": "SVR works well with sparse data",
            "C": "SVR is less interpretable than Lasso",
            "D": "SVR always produces linear decision boundaries"
          }
        },
        {
          "number": 9,
          "difficulty": "Hard",
          "type": "single_select",
          "question": "What is a limitation of SVR compared to Lasso regression?",
          "options": {
            "A": "SVR cannot handle non-linear relationships",
            "B": "SVR is less interpretable due to non-linearities",
            "C": "SVR cannot process sparse data",
            "D": "SVR always removes unimportant features"
          }
        },
        {
          "number": 10,
          "difficulty": "Unknown",
          "type": "single_select",
          "question": "**(Hard, Select all that apply):** According to the lecture, which of the following are true about regularization in regression models?",
          "options": {
            "A": "Regularization penalizes large coefficients",
            "B": "Regularization can help mitigate model complexity",
            "C": "L1 regularization encourages sparsity",
            "D": "Regularization is only used in unsupervised models"
          }
        }
      ]
    }
  ]
}