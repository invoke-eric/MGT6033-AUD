# Quiz Questions

## Section 1: NLP Terminology & Foundations

1. **(Easy)** What is the definition of a "token" in NLP?  
A. Any numeric value in a dataset  
B. A smaller piece of text produced by breaking down a document  
C. The last word in a document  
D. A specific stop word  

2. **(Medium) Select all that apply:** Which of the following are examples of tokens as described in the lecture?  
A. Characters  
B. Words  
C. Sentences  
D. Paragraphs  

3. **(Medium)** What is an "N-gram"?  
A. A punctuation mark in a sentence  
B. A combination of 'n' consecutive words or tokens  
C. Another word for a lemma  
D. A part-of-speech tag  

4. **(Medium) Select all that apply:** According to the materials, what are the most common levels at which text is tokenized?  
A. Sentences  
B. Words  
C. Characters  
D. Pages  

5. **(Hard)** What distinguishes a lemma from a stem in NLP?  
A. Lemmas always coincide with valid dictionary words; stems may not  
B. Stems are always longer than lemmas  
C. Stems are determined by part-of-speech; lemmas aren’t  
D. Stems do not require rules; lemmas do  

6. **(Medium)** What is a stop word?  
A. A word that always signals the end of a sentence  
B. A frequently occurring, mostly semantically low-value word  
C. A unique noun in a document  
D. Any verb in the passive voice  

7. **(Hard) Select all that apply:** Which words would most likely be included in a stop word dictionary?  
A. The  
B. Is  
C. Very  
D. Table  

## Section 2: Tokenization Techniques & Challenges

8. **(Medium)** In the provided example (“Let’s tokenize! Isn’t this easy?”), what is a potential issue with simple whitespace tokenization?  
A. It separates contractions into separate words  
B. Punctuation remains attached to words, affecting consistency  
C. It changes all words to lowercase  
D. It counts stop words twice  

9. **(Hard) Select all that apply:** What are advantages of rules-based tokenization, according to the lecture?  
A. It can handle contractions like “isn’t” by splitting into “is” and “n’t”  
B. It allows separation of ending punctuation from words  
C. It is perfect for all text types  
D. It standardizes tokens better across contexts  

10. **(Hard)** What is a known limitation of tokenizing possessives and contractions (such as "'s")?  
A. They always indicate possession  
B. They can represent different meanings such as “is”, “us”, or ownership, causing ambiguity  
C. They are never separated from root words  
D. Only stemmers can handle them correctly  

