# Answer Key

## Section 1: NLP Terminology & Foundations

1. **Correct Answer:** B  
**Explanation:** A token is defined as a smaller piece of text produced by breaking down a document.  
**Verbatim Quote:** "Tokenization refers to the breaking down of text into smaller pieces." (3.2-NLP-terminology-and-Tokenization.txt)

2. **Correct Answers:** A, B, C  
**Explanation:** Tokens can be characters, words, or sentences, as detailed in the materials.  
**Verbatim Quote:** "We could define a token as a character... The vast majority of the time, we will tokenize directly to words or maybe sentences..." (3.2-NLP-terminology-and-Tokenization.txt)

3. **Correct Answer:** B  
**Explanation:** An N-gram is any word combination of up to n elements—e.g., bigram or trigram.  
**Verbatim Quote:** "An N-gram refers to a word combination of up to n elements. For example a bigram has two words and the trigram three." (3.2-NLP-terminology-and-Tokenization.txt)

4. **Correct Answers:** A, B  
**Explanation:** Most tokenization is done on sentences and words.  
**Verbatim Quote:** "The vast majority of the time, we will tokenize directly to words or maybe sentences..." (3.2-NLP-terminology-and-Tokenization.txt)

5. **Correct Answer:** A  
**Explanation:** Lemmas are valid dictionary words and often depend on part-of-speech; stems may not be actual words.  
**Verbatim Quote:** "The obvious benefit of using lemmas is that they are actual words. ... Stemming relies completely on common letter patterns." (3.2-NLP-terminology-and-Tokenization.txt)

6. **Correct Answer:** B  
**Explanation:** Stop words are commonly occurring, mostly semantically low-value words.  
**Verbatim Quote:** "Stop words refer to a set of very commonly occurring and syntactically necessary, but otherwise mostly meaningless words." (3.2-NLP-terminology-and-Tokenization.txt)

7. **Correct Answers:** A, B, C  
**Explanation:** "The", "Is", and "Very" are included examples; "Table" is not typically a stop word.  
**Verbatim Quote:** "The is a stop word. ... Is another stop word. ... Some stop word dictionaries may also include the word very..." (3.2-NLP-terminology-and-Tokenization.txt)

## Section 2: Tokenization Techniques & Challenges

8. **Correct Answer:** B  
**Explanation:** Words may keep attached punctuation, which affects consistency (e.g., "easy" vs. "easy?").  
**Verbatim Quote:** "Do you see any issues with this approach? ... tokenize and easy have their punctuation included." (3.2-NLP-terminology-and-Tokenization.txt)

9. **Correct Answers:** A, B, D  
**Explanation:** Rules-based tokenization can split contractions, separate punctuation, and improve token standardization.  
**Verbatim Quote:** "Several words are properly tokenized as well, like let, tokenize, is, this, easy. We can also see that 's is retained as a token as is n't ... this approach does seem to work best." (3.2-NLP-terminology-and-Tokenization.txt)

10. **Correct Answer:** B  
**Explanation:** "'s" can indicate various meanings—possession, contraction for "is", or "us"—causing ambiguity in tokenization.  
**Verbatim Quote:** "Unfortunately, 's can indicate a possessive, the word is, the word us, and maybe even a few others." (3.2-NLP-terminology-and-Tokenization.txt)
